{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling manifest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pulling 8934d96d3f08: 100%|██████████| 3.83G/3.83G [00:00<00:00, 3.82TB/s]\n",
      "pulling 8c17c2ebb0ea: 100%|██████████| 7.02k/7.02k [00:00<?, ?B/s]\n",
      "pulling 7c23fb36d801: 100%|██████████| 4.77k/4.77k [00:00<?, ?B/s]\n",
      "pulling 2e0493f67d0c: 100%|██████████| 59.0/59.0 [00:00<?, ?B/s]\n",
      "pulling fa304d675061: 100%|██████████| 91.0/91.0 [00:00<?, ?B/s]\n",
      "pulling 42ba7f8a01dd: 100%|██████████| 557/557 [00:00<?, ?B/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verifying sha256 digest\n",
      "writing manifest\n",
      "success\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Pulling\n",
    "from tqdm import tqdm\n",
    "from ollama import pull\n",
    "\n",
    "\n",
    "current_digest, bars = '', {}\n",
    "for progress in pull('llama2', stream=True):\n",
    "  digest = progress.get('digest', '')\n",
    "  if digest != current_digest and current_digest in bars:\n",
    "    bars[current_digest].close()\n",
    "\n",
    "  if not digest:\n",
    "    print(progress.get('status'))\n",
    "    continue\n",
    "\n",
    "  if digest not in bars and (total := progress.get('total')):\n",
    "    bars[digest] = tqdm(total=total, desc=f'pulling {digest[7:19]}', unit='B', unit_scale=True)\n",
    "\n",
    "  if completed := progress.get('completed'):\n",
    "    bars[digest].update(completed - bars[digest].n)\n",
    "\n",
    "  current_digest = digest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling manifest\n",
      "pulling 8934d96d3f08\n",
      "pulling 8c17c2ebb0ea\n",
      "pulling 7c23fb36d801\n",
      "pulling 2e0493f67d0c\n",
      "pulling fa304d675061\n",
      "pulling 42ba7f8a01dd\n",
      "verifying sha256 digest\n",
      "writing manifest\n",
      "success\n",
      "\n",
      "\n",
      "Hello there! It's nice to meet you. How are you today?\n",
      "\n",
      "\n",
      "llama2:latest: 38% CPU/62% GPU\n"
     ]
    }
   ],
   "source": [
    "#PS\n",
    "\n",
    "from ollama import ps, pull, chat\n",
    "\n",
    "response = pull('llama2', stream=True)\n",
    "progress_states = set()\n",
    "for progress in response:\n",
    "  if progress.get('status') in progress_states:\n",
    "    continue\n",
    "  progress_states.add(progress.get('status'))\n",
    "  print(progress.get('status'))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "response = chat('llama2', messages=[{'role': 'user', 'content': 'Hello!'}])\n",
    "print(response['message']['content'])\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "response = ps()\n",
    "\n",
    "name = response['models'][0]['name']\n",
    "size = response['models'][0]['size']\n",
    "size_vram = response['models'][0]['size_vram']\n",
    "\n",
    "if size == size_vram:\n",
    "  print(f'{name}: 100% GPU')\n",
    "elif not size_vram:\n",
    "  print(f'{name}: 100% CPU')\n",
    "else:\n",
    "  size_cpu = size - size_vram\n",
    "  cpu_percent = round(size_cpu / size * 100)\n",
    "  print(f'{name}: {cpu_percent}% CPU/{100 - cpu_percent}% GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The sky appears blue because of a phenomenon called Rayleigh scattering. When sunlight enters Earth's atmosphere, it encounters tiny molecules of gases such as nitrogen and oxygen. These molecules scatter the light in all directions, but they scatter shorter (blue) wavelengths more than longer (red) wavelengths. This is known as Rayleigh scattering.\n",
      "\n",
      "As a result of this scattering, the blue light is dispersed throughout the atmosphere, giving the sky its blue appearance. The blue light can travel much farther through the atmosphere than the red light, so even when the sun is behind the horizon, the blue light can still reach our eyes and give us a blue sky.\n",
      "\n",
      "In addition to Rayleigh scattering, there are other factors that can contribute to the color of the sky, such as dust particles, water vapor, and pollution. However, these factors generally have less of an impact on the overall appearance of the sky than Rayleigh scattering.\n",
      "\n",
      "It's worth noting that the color of the sky can vary depending on the time of day and atmospheric conditions. For example, during sunrise and sunset, the sky can take on hues of red, orange, and pink due to the angle of the sunlight and the scattering of light by atmospheric particles.\n"
     ]
    }
   ],
   "source": [
    "#Chat_stream\n",
    "from ollama import chat\n",
    "\n",
    "\n",
    "messages = [\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "]\n",
    "\n",
    "for part in chat('llama2', messages=messages, stream=True):\n",
    "  print(part['message']['content'], end='', flush=True)\n",
    "\n",
    "# end with a newline\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The sky appears blue because of a phenomenon called Rayleigh scattering, which occurs when sunlight enters Earth's atmosphere. The sunlight encounters tiny molecules of gases in the air, such as nitrogen and oxygen, which scatters the light in all directions.\n",
      "\n",
      "The shorter, blue wavelengths of light are scattered more than the longer, red wavelengths, resulting in a blue sky. This is known as Rayleigh scattering, named after the English physicist Lord Rayleigh, who first described the phenomenon in the late 19th century.\n",
      "\n",
      "The blue color of the sky can also be affected by other factors such as air pollution, dust, and water vapor. However, these effects are generally not as pronounced as the Rayleigh scattering effect.\n",
      "\n",
      "It's worth noting that the blue color of the sky is not always constant and can vary depending on the time of day, weather conditions, and altitude. For example, during sunrise and sunset, the sky can take on hues of red, orange, and pink due to the angle of the sunlight and the scattering of light by atmospheric particles.\n"
     ]
    }
   ],
   "source": [
    "#Chat \n",
    "import ollama\n",
    "import os\n",
    "from ollama import create\n",
    "from ollama import chat\n",
    "\n",
    "messages = [\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "]\n",
    "\n",
    "response = chat('llama2', messages=messages)\n",
    "print(response['message']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The sky appears blue because of a phenomenon called Rayleigh scattering. When sunlight enters Earth's atmosphere, it encounters tiny molecules of gases such as nitrogen and oxygen. These molecules scatter the light in all directions, but they scatter shorter (blue) wavelengths more than longer (red) wavelengths. This is known as Rayleigh scattering.\n",
      "\n",
      "As a result of this scattering, the blue light is distributed throughout the atmosphere, giving the sky its blue color. The red light, on the other hand, passes through the atmosphere mostly unscattered and reaches our eyes directly, appearing redder than the blue light. This is why the sky can appear different shades of blue during different times of day and in different conditions, depending on the amount of sunlight and the amount of particles in the air.\n",
      "\n",
      "It's worth noting that the color of the sky can also be affected by other factors such as pollution, dust, and water vapor, which can scatter light in different ways and produce a range of colors in the sky. However, the main reason why the sky appears blue is due to Rayleigh scattering."
     ]
    }
   ],
   "source": [
    "#Gerenate-stream \n",
    "from ollama import generate\n",
    "\n",
    "\n",
    "for part in generate('llama2', 'Why is the sky blue?', stream=True):\n",
    "  print(part['response'], end='', flush=True)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The sky appears blue because of a phenomenon called Rayleigh scattering. When sunlight enters Earth's atmosphere, it encounters tiny molecules of gases such as nitrogen and oxygen. These molecules scatter the light in all directions, but they scatter shorter (blue) wavelengths more than longer (red) wavelengths. This is known as Rayleigh scattering.\n",
      "\n",
      "As a result of this scattering, the blue light is dispersed throughout the atmosphere, giving the sky its blue color. The red light, on the other hand, travels through the atmosphere without being scattered, so it appears more direct and reaches our eyes as red light. This is why the sky can sometimes appear to be a different color depending on the time of day and atmospheric conditions.\n",
      "\n",
      "It's worth noting that the blue color of the sky is not the only reason why we see colors in nature. The colors we see in flowers, leaves, and other objects are also due to the way light interacts with their surfaces and the pigments they contain.\n"
     ]
    }
   ],
   "source": [
    "#Generate\n",
    "from ollama import generate\n",
    "\n",
    "\n",
    "response = generate('llama2', 'Why is the sky blue?')\n",
    "print(response['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xkcd #570: Somewhere out there is a company that has actually figured out how to enlarge penises, and it's helpless to reach potential customers.\n",
      "link: https://xkcd.com/570\n",
      "---\n",
      "\n",
      "The comic you provided is a classic example of a \"before and after\" joke. It shows two contrasting scenarios, with the first one depicting a messy and disorganized space, and the second one showing a neat and organized space. The punchline of the comic is that the before and after scenes are the same room, implying that the change in organization is superficial and does not actually solve any underlying problems.\n",
      "\n",
      "Here's a breakdown of the comic:\n",
      "\n",
      "1. The first panel shows a cluttered and disorganized room with clothes scattered all over the floor, empty food boxes and trash cans, and general chaos.\n",
      "2. The second panel shows the same room, but now it is neat and organized. There are clean clothes in the closet, food boxes are closed and put away, and the trash cans are emptied.\n",
      "3. The punchline of the comic is revealed when we see that the \"after\" scene is actually the same room as the \"before\" scene. This reveals that the change in organization is superficial and does not address any underlying problems.\n",
      "\n",
      "Overall, the comic is a humorous way to poke fun at the idea of trying to fix problems by just cleaning up the surface level without addressing the root causes.\n"
     ]
    }
   ],
   "source": [
    "#Multimodal \n",
    "import random\n",
    "import httpx\n",
    "from ollama import generate\n",
    "\n",
    "# Fetch the latest XKCD comic metadata\n",
    "latest = httpx.get('https://xkcd.com/info.0.json')\n",
    "latest.raise_for_status()\n",
    "\n",
    "# You can manually provide a number for the comic, or use a random comic number.\n",
    "# Instead of using `sys.argv`, manually set the comic number here:\n",
    "num = random.randint(1, latest.json().get('num'))  # Random comic number\n",
    "\n",
    "# Fetch the specific comic based on the number\n",
    "comic = httpx.get(f'https://xkcd.com/{num}/info.0.json')\n",
    "comic.raise_for_status()\n",
    "\n",
    "# Print out comic details\n",
    "print(f'xkcd #{comic.json().get(\"num\")}: {comic.json().get(\"alt\")}')\n",
    "print(f'link: https://xkcd.com/{num}')\n",
    "print('---')\n",
    "\n",
    "# Fetch the image from the comic URL\n",
    "raw = httpx.get(comic.json().get('img'))\n",
    "raw.raise_for_status()\n",
    "\n",
    "# Generate explanation for the comic using the 'llava' model\n",
    "for response in generate('llama2', 'explain this comic:', images=[raw.content], stream=True):\n",
    "    print(response['response'], end='', flush=True)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "llama2 does not support insert",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 10\u001b[0m\n\u001b[0;32m      3\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\u001b[38;5;124mdef remove_non_ascii(s: str) -> str:\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m      6\u001b[0m suffix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124m    return result\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 10\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mllama2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m  \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m  \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m  \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_predict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m<EOT>\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m  \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ollama\\_client.py:163\u001b[0m, in \u001b[0;36mClient.generate\u001b[1;34m(self, model, prompt, suffix, system, template, context, stream, raw, format, images, options, keep_alive)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model:\n\u001b[0;32m    161\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m RequestError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmust provide a model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/generate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m  \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msuffix\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemplate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mraw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m_encode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mformat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkeep_alive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m  \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ollama\\_client.py:99\u001b[0m, in \u001b[0;36mClient._request_stream\u001b[1;34m(self, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request_stream\u001b[39m(\n\u001b[0;32m     94\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     95\u001b[0m   \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m     96\u001b[0m   stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     97\u001b[0m   \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     98\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Mapping[\u001b[38;5;28mstr\u001b[39m, Any], Iterator[Mapping[\u001b[38;5;28mstr\u001b[39m, Any]]]:\n\u001b[1;32m---> 99\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ollama\\_client.py:75\u001b[0m, in \u001b[0;36mClient._request\u001b[1;34m(self, method, url, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m   response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 75\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext, e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[1;31mResponseError\u001b[0m: llama2 does not support insert"
     ]
    }
   ],
   "source": [
    "#Fill-middle\n",
    "from ollama import generate\n",
    "\n",
    "prompt = '''def remove_non_ascii(s: str) -> str:\n",
    "    \"\"\" '''\n",
    "\n",
    "suffix = \"\"\"\n",
    "    return result\n",
    "\"\"\"\n",
    "\n",
    "response = generate(\n",
    "  model='llama2',\n",
    "  prompt=prompt,\n",
    "  suffix=suffix,\n",
    "  options={\n",
    "    'num_predict': 128,\n",
    "    'temperature': 0,\n",
    "    'top_p': 0.9,\n",
    "    'stop': ['<EOT>'],\n",
    "  },\n",
    ")\n",
    "\n",
    "print(response['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: python main.py <name> <filepath>\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "#Create\n",
    "import sys\n",
    "\n",
    "from ollama import create\n",
    "\n",
    "\n",
    "args = sys.argv[1:]\n",
    "if len(args) == 2:\n",
    "  # create from local file\n",
    "  path = args[1]\n",
    "else:\n",
    "  print('usage: python main.py <name> <filepath>')\n",
    "  sys.exit(1)\n",
    "\n",
    "# TODO: update to real Modelfile values\n",
    "modelfile = f\"\"\"\n",
    "FROM {path}\n",
    "\"\"\"\n",
    "\n",
    "for response in create(model=args[0], modelfile=modelfile, stream=True):\n",
    "  print(response['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 57\u001b[0m\n\u001b[0;32m     53\u001b[0m       \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m   \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mEOFError\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m   \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\runners.py:190\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug, loop_factory)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug, loop_factory\u001b[38;5;241m=\u001b[39mloop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "#Async chat-stream\n",
    "import shutil\n",
    "import asyncio\n",
    "import argparse\n",
    "\n",
    "import ollama\n",
    "\n",
    "\n",
    "async def speak(speaker, content):\n",
    "  if speaker:\n",
    "    p = await asyncio.create_subprocess_exec(speaker, content)\n",
    "    await p.communicate()\n",
    "\n",
    "\n",
    "async def main():\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument('--speak', default=False, action='store_true')\n",
    "  args = parser.parse_args()\n",
    "\n",
    "  speaker = None\n",
    "  if not args.speak:\n",
    "    ...\n",
    "  elif say := shutil.which('say'):\n",
    "    speaker = say\n",
    "  elif (espeak := shutil.which('espeak')) or (espeak := shutil.which('espeak-ng')):\n",
    "    speaker = espeak\n",
    "\n",
    "  client = ollama.AsyncClient()\n",
    "\n",
    "  messages = []\n",
    "\n",
    "  while True:\n",
    "    if content_in := input('>>> '):\n",
    "      messages.append({'role': 'user', 'content': content_in})\n",
    "\n",
    "      content_out = ''\n",
    "      message = {'role': 'assistant', 'content': ''}\n",
    "      async for response in await client.chat(model='mistral', messages=messages, stream=True):\n",
    "        if response['done']:\n",
    "          messages.append(message)\n",
    "\n",
    "        content = response['message']['content']\n",
    "        print(content, end='', flush=True)\n",
    "\n",
    "        content_out += content\n",
    "        if content in ['.', '!', '?', '\\n']:\n",
    "          await speak(speaker, content_out)\n",
    "          content_out = ''\n",
    "\n",
    "        message['content'] += content\n",
    "\n",
    "      if content_out:\n",
    "        await speak(speaker, content_out)\n",
    "      print()\n",
    "\n",
    "\n",
    "try:\n",
    "  asyncio.run(main())\n",
    "except (KeyboardInterrupt, EOFError):\n",
    "  ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 87\u001b[0m\n\u001b[0;32m     83\u001b[0m   \u001b[38;5;28mprint\u001b[39m(final_response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Run the async function\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mllama2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\runners.py:190\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug, loop_factory)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug, loop_factory\u001b[38;5;241m=\u001b[39mloop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "#Tools\n",
    "import json\n",
    "import ollama\n",
    "import asyncio\n",
    "\n",
    "\n",
    "# Simulates an API call to get flight times\n",
    "# In a real application, this would fetch data from a live database or API\n",
    "def get_flight_times(departure: str, arrival: str) -> str:\n",
    "  flights = {\n",
    "    'NYC-LAX': {'departure': '08:00 AM', 'arrival': '11:30 AM', 'duration': '5h 30m'},\n",
    "    'LAX-NYC': {'departure': '02:00 PM', 'arrival': '10:30 PM', 'duration': '5h 30m'},\n",
    "    'LHR-JFK': {'departure': '10:00 AM', 'arrival': '01:00 PM', 'duration': '8h 00m'},\n",
    "    'JFK-LHR': {'departure': '09:00 PM', 'arrival': '09:00 AM', 'duration': '7h 00m'},\n",
    "    'CDG-DXB': {'departure': '11:00 AM', 'arrival': '08:00 PM', 'duration': '6h 00m'},\n",
    "    'DXB-CDG': {'departure': '03:00 AM', 'arrival': '07:30 AM', 'duration': '7h 30m'},\n",
    "  }\n",
    "\n",
    "  key = f'{departure}-{arrival}'.upper()\n",
    "  return json.dumps(flights.get(key, {'error': 'Flight not found'}))\n",
    "\n",
    "\n",
    "async def run(model: str):\n",
    "  client = ollama.AsyncClient()\n",
    "  # Initialize conversation with a user query\n",
    "  messages = [{'role': 'user', 'content': 'What is the flight time from New York (NYC) to Los Angeles (LAX)?'}]\n",
    "\n",
    "  # First API call: Send the query and function description to the model\n",
    "  response = await client.chat(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    tools=[\n",
    "      {\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "          'name': 'get_flight_times',\n",
    "          'description': 'Get the flight times between two cities',\n",
    "          'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "              'departure': {\n",
    "                'type': 'string',\n",
    "                'description': 'The departure city (airport code)',\n",
    "              },\n",
    "              'arrival': {\n",
    "                'type': 'string',\n",
    "                'description': 'The arrival city (airport code)',\n",
    "              },\n",
    "            },\n",
    "            'required': ['departure', 'arrival'],\n",
    "          },\n",
    "        },\n",
    "      },\n",
    "    ],\n",
    "  )\n",
    "\n",
    "  # Add the model's response to the conversation history\n",
    "  messages.append(response['message'])\n",
    "\n",
    "  # Check if the model decided to use the provided function\n",
    "  if not response['message'].get('tool_calls'):\n",
    "    print(\"The model didn't use the function. Its response was:\")\n",
    "    print(response['message']['content'])\n",
    "    return\n",
    "\n",
    "  # Process function calls made by the model\n",
    "  if response['message'].get('tool_calls'):\n",
    "    available_functions = {\n",
    "      'get_flight_times': get_flight_times,\n",
    "    }\n",
    "    for tool in response['message']['tool_calls']:\n",
    "      function_to_call = available_functions[tool['function']['name']]\n",
    "      function_response = function_to_call(tool['function']['arguments']['departure'], tool['function']['arguments']['arrival'])\n",
    "      # Add function response to the conversation\n",
    "      messages.append(\n",
    "        {\n",
    "          'role': 'tool',\n",
    "          'content': function_response,\n",
    "        }\n",
    "      )\n",
    "\n",
    "  # Second API call: Get final response from the model\n",
    "  final_response = await client.chat(model=model, messages=messages)\n",
    "  print(final_response['message']['content'])\n",
    "\n",
    "\n",
    "# Run the async function\n",
    "asyncio.run(run('llama2'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
